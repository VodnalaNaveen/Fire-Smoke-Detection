# 🔥 Fire & Smoke Detection Using YOLO11n

A complete end-to-end **Fire and Smoke Detection System** using **YOLO11n**, trained on a **custom-labeled dataset annotated with LabelImg**. The model supports detection from **images**, **videos**, and **real-time webcam**. This project also includes **ONNX export** for optimized, cross-platform inference on edge devices.

---

## 📌 Key Features

- ✅ Real-time Fire & Smoke detection  
- ✅ Trained on custom-labeled dataset  
- ✅ Image, Video & Webcam support  
- ✅ Optimized ONNX export  
- ✅ Clean, scalable code with YOLO11n  

---

## 📦 Dataset: Custom Collection & Labeling

The dataset used in this project was **manually collected** from various sources and **annotated using LabelImg** in the YOLO format. This approach ensures complete control over class distribution, image quality, and annotation accuracy.

---

## 🧠 Model Training (YOLO11n)

A lightweight YOLO model variant, **`yolo11n.pt`**, was used as the base model. It was trained for 50 epochs on the custom-labeled dataset using the YOLO training pipeline. After training, the `best.pt` weights were selected for further inference and deployment.

---

## 🔄 Export to ONNX

### ❓ Why Export to ONNX?

Exporting your trained model to **ONNX (Open Neural Network Exchange)** format unlocks powerful deployment capabilities beyond the training environment. ONNX serves as a bridge across different deep learning frameworks and platforms, offering the following benefits:

 - **🚀 Cross-Platform Compatibility**:
   Run your YOLO model on various platforms like PyTorch, TensorFlow, OpenVINO, or even mobile and embedded devices.

 - **⚡ Hardware-Accelerated Inference**:
   Use hardware-specific runtimes such as TensorRT, OpenVINO, and ONNX Runtime for faster, optimized model inference.

 - **📦 Lightweight & Production-Ready**:
   ONNX models are compact, making them ideal for real-time applications and resource-constrained environments.

 - **🔄 Framework Independence**:
   ONNX models can be used across environments like C++, Java, or web-based applications without relying on the original training framework.

---

## 🚀 Inference Options

This project supports detection from multiple input sources using the trained YOLO11n model in ONNX format:

### 📷 Real-Time Webcam Inference

Run the ONNX model directly on your system’s webcam. It captures live frames, performs fire/smoke detection, and displays the annotated output in real time. Optionally, output frames can be saved to disk.

### 🖼️ Image Inference

Detect fire or smoke in static images. The model processes the input image and returns annotated results with bounding boxes and class labels.

### 🎞️ Video Inference

Apply fire and smoke detection to full video files. Each frame is processed individually, and the output can be viewed or saved as a video with annotated detections.

---

## 🧾 Requirements

```
ultralytics
opencv-python
```

---

## 📁 File Structure

```
├── object_detection.ipynb     # YOLO11n training, ONNX export
├── detection.ipynb            # Inference: Image, Video, Webcam detection using ONNX
├── runs                       # Auto-generated by YOLO11n after training (logs, weights)
├── image                      # sample images for testing
└── video                      # sample videos for detection
```
