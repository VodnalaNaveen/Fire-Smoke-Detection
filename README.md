# ğŸ”¥ Fire & Smoke Detection Using YOLO11n

A complete end-to-end **Fire and Smoke Detection System** using **YOLO11n**, trained on a **custom-labeled dataset annotated with LabelImg**. The model supports detection from **images**, **videos**, and **real-time webcam**. This project also includes **ONNX export** for optimized, cross-platform inference on edge devices.

---

## ğŸ“Œ Key Features

- âœ… Real-time Fire & Smoke detection  
- âœ… Trained on custom-labeled dataset  
- âœ… Image, Video & Webcam support  
- âœ… Optimized ONNX export  
- âœ… Clean, scalable code with YOLO11n  

---

## ğŸ“¦ Dataset: Custom Collection & Labeling

The dataset used in this project was **manually collected** from various sources and **annotated using LabelImg** in the YOLO format. This approach ensures complete control over class distribution, image quality, and annotation accuracy.

---

## ğŸ§  Model Training (YOLO11n)

A lightweight YOLO model variant, **`yolo11n.pt`**, was used as the base model. It was trained for 50 epochs on the custom-labeled dataset using the YOLO training pipeline. After training, the `best.pt` weights were selected for further inference and deployment.

---

## ğŸ”„ Export to ONNX

### â“ Why Export to ONNX?

Exporting your trained model to **ONNX (Open Neural Network Exchange)** format unlocks powerful deployment capabilities beyond the training environment. ONNX serves as a bridge across different deep learning frameworks and platforms, offering the following benefits:

 - **ğŸš€ Cross-Platform Compatibility**:
   Run your YOLO model on various platforms like PyTorch, TensorFlow, OpenVINO, or even mobile and embedded devices.

 - **âš¡ Hardware-Accelerated Inference**:
   Use hardware-specific runtimes such as TensorRT, OpenVINO, and ONNX Runtime for faster, optimized model inference.

 - **ğŸ“¦ Lightweight & Production-Ready**:
   ONNX models are compact, making them ideal for real-time applications and resource-constrained environments.

 - **ğŸ”„ Framework Independence**:
   ONNX models can be used across environments like C++, Java, or web-based applications without relying on the original training framework.

---

## ğŸš€ Inference Options

This project supports detection from multiple input sources using the trained YOLO11n model in ONNX format:

### ğŸ“· Real-Time Webcam Inference

Run the ONNX model directly on your systemâ€™s webcam. It captures live frames, performs fire/smoke detection, and displays the annotated output in real time. Optionally, output frames can be saved to disk.

### ğŸ–¼ï¸ Image Inference

Detect fire or smoke in static images. The model processes the input image and returns annotated results with bounding boxes and class labels.

### ğŸï¸ Video Inference

Apply fire and smoke detection to full video files. Each frame is processed individually, and the output can be viewed or saved as a video with annotated detections.

---

## ğŸ§¾ Requirements

```
ultralytics
opencv-python
```

---

## ğŸ“ File Structure

```
â”œâ”€â”€ object_detection.ipynb     # YOLO11n training, ONNX export
â”œâ”€â”€ detection.ipynb            # Inference: Image, Video, Webcam detection using ONNX
â”œâ”€â”€ runs                       # Auto-generated by YOLO11n after training (logs, weights)
â”œâ”€â”€ image                      # sample images for testing
â””â”€â”€ video                      # sample videos for detection
```
